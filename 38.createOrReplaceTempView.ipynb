{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/23 23:17:44 WARN Utils: Your hostname, akshay-vm resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "24/06/23 23:17:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/23 23:17:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/23 23:17:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/06/23 23:17:46 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/home/akshay/spark-3.5.1-bin-hadoop3')\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"spark_tutorials_1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, \"Alice\", \"Female\", 60000, \"HR\"),\n",
    "    (2, \"Bob\", \"Male\", 80000, \"Engineering\"),\n",
    "    (3, \"Charlie\", \"Male\", 75000, \"Marketing\"),\n",
    "    (4, \"Diana\", \"Female\", 90000, \"Finance\"),\n",
    "    (5, \"Eve\", \"Female\", 70000, \"Engineering\"),\n",
    "    (6, \"Frank\", \"Male\", 85000, \"HR\"),\n",
    "    (7, \"Gina\", \"Female\", 65000, \"Marketing\"),\n",
    "    (8, \"Henry\", \"Male\", 95000, \"Finance\"),\n",
    "    (9, \"Irene\", \"Female\", 72000, \"Engineering\"),\n",
    "    (10, \"John\", \"Male\", 78000, \"HR\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = [\"id\", \"name\",\"gender\",\"salary\",\"dept\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+------+-----------+\n",
      "| id|   name|gender|salary|       dept|\n",
      "+---+-------+------+------+-----------+\n",
      "|  1|  Alice|Female| 60000|         HR|\n",
      "|  2|    Bob|  Male| 80000|Engineering|\n",
      "|  3|Charlie|  Male| 75000|  Marketing|\n",
      "|  4|  Diana|Female| 90000|    Finance|\n",
      "|  5|    Eve|Female| 70000|Engineering|\n",
      "|  6|  Frank|  Male| 85000|         HR|\n",
      "|  7|   Gina|Female| 65000|  Marketing|\n",
      "|  8|  Henry|  Male| 95000|    Finance|\n",
      "|  9|  Irene|Female| 72000|Engineering|\n",
      "| 10|   John|  Male| 78000|         HR|\n",
      "+---+-------+------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `createOrReplaceTempView` in PySpark\n",
    "\n",
    "### Syntax\n",
    "\n",
    "The syntax for `createOrReplaceTempView` in PySpark is as follows:\n",
    "\n",
    "```python\n",
    "DataFrame.createOrReplaceTempView(viewName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "In PySpark, createOrReplaceTempView is a method used to create or replace a temporary view from a DataFrame. This temporary view allows you to query the DataFrame using SQL-like syntax, enabling seamless integration of SQL operations with Spark's DataFrame API.\n",
    "#### Key Points\n",
    "\n",
    "* Temporary View: Registers the DataFrame as a temporary table or view within the Spark Session.\n",
    "* Scope: Exists only within the session where it was created and is automatically removed when the session ends.\n",
    "* Replacement: If a temporary view with the same name already exists, it will be replaced with the new DataFrame.\n",
    "* SQL Queries: Enables performing SQL queries directly on the registered temporary view, leveraging Spark's SQL capabilities.\n",
    "\n",
    "#### Functionality\n",
    "\n",
    "The primary functionality of createOrReplaceTempView includes:\n",
    "\n",
    "* SQL Integration: Facilitates SQL-like operations on DataFrames, allowing users to query data using familiar SQL syntax.\n",
    "* Data Manipulation: Provides a structured way to manipulate and transform data within the DataFrame using SQL queries.\n",
    "* Temporary Storage: Stores the DataFrame temporarily as a view, enabling iterative data exploration and analysis.\n",
    "\n",
    "#### Benefits\n",
    "\n",
    "* SQL Compatibility: Allows SQL users to leverage their SQL skills directly on Spark DataFrames.\n",
    "* Performance Optimization: Utilizes Spark's optimized execution engine for efficient query processing.\n",
    "* Flexibility: Supports seamless integration with other Spark operations and libraries, enhancing productivity and code maintainability.\n",
    "* Data Exploration: Enables interactive data exploration and ad-hoc querying of DataFrame content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"employee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+------+-----------+\n",
      "| id| name|gender|salary|       dept|\n",
      "+---+-----+------+------+-----------+\n",
      "|  1|Alice|Female| 60000|         HR|\n",
      "|  4|Diana|Female| 90000|    Finance|\n",
      "|  5|  Eve|Female| 70000|Engineering|\n",
      "|  7| Gina|Female| 65000|  Marketing|\n",
      "|  9|Irene|Female| 72000|Engineering|\n",
      "+---+-----+------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.sql(\"SELECT * FROM employee WHERE gender = 'Female'\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
