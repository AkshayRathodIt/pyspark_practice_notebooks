{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/18 19:12:03 WARN Utils: Your hostname, akshay-vm resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "24/06/18 19:12:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/18 19:12:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/home/akshay/spark-3.5.1-bin-hadoop3')\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"spark_tutorials_1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, 'Alice', 'Female', 60000, 'HR'),\n",
    "    (2, 'Bob', 'Male', 75000, 'Engineering'),\n",
    "    (3, 'Charlie', 'Male', 50000, 'Marketing'),\n",
    "    (4, 'David', 'Male', 90000, 'Finance'),\n",
    "    (5, 'Eve', 'Female', 55000, 'HR'),\n",
    "    (6, 'Frank', 'Male', 80000, 'Engineering'),\n",
    "    (7, 'Grace', 'Female', 70000, 'Marketing'),\n",
    "    (8, 'Henry', 'Male', 62000, 'Finance'),\n",
    "    (9, 'Ivy', 'Female', 68000, 'HR'),\n",
    "    (10, 'Jack', 'Male', 72000, 'Engineering'),\n",
    "    (11, 'Kate', 'Female', 48000, 'Marketing'),\n",
    "    (12, 'Leo', 'Male', 85000, 'Finance'),\n",
    "    (13, 'Mia', 'Female', 61000, 'HR'),\n",
    "    (14, 'Nathan', 'Male', 77000, 'Engineering'),\n",
    "    (15, 'Olivia', 'Female', 69000, 'Marketing'),\n",
    "    (16, 'Peter', 'Male', 53000, 'Finance'),\n",
    "    (17, 'Quinn', 'Female', 62000, 'HR'),\n",
    "    (18, 'Ryan', 'Male', 74000, 'Engineering'),\n",
    "    (19, 'Samantha', 'Female', 68000, 'Marketing'),\n",
    "    (20, 'Tom', 'Male', 58000, 'Finance'),\n",
    "    (21, 'Uma', 'Female', 64000, 'HR'),\n",
    "    (22, 'Vincent', 'Male', 71000, 'Engineering'),\n",
    "    (23, 'Wendy', 'Female', 66000, 'Marketing'),\n",
    "    (24, 'Xavier', 'Male', 79000, 'Finance'),\n",
    "    (25, 'Yvonne', 'Female', 59000, 'HR'),\n",
    "    (26, 'Zack', 'Male', 73000, 'Engineering'),\n",
    "    (27, 'Emily', 'Female', 67000, 'Marketing'),\n",
    "    (28, 'Michael', 'Male', 82000, 'Finance'),\n",
    "    (29, 'Sophia', 'Female', 60000, 'HR'),\n",
    "    (30, 'Jacob', 'Male', 76000, 'Engineering'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = [\"id\",\"name\",\"gender\",\"salary\",\"dept\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+-----------+\n",
      "| id|    name|gender|salary|       dept|\n",
      "+---+--------+------+------+-----------+\n",
      "|  1|   Alice|Female| 60000|         HR|\n",
      "|  2|     Bob|  Male| 75000|Engineering|\n",
      "|  3| Charlie|  Male| 50000|  Marketing|\n",
      "|  4|   David|  Male| 90000|    Finance|\n",
      "|  5|     Eve|Female| 55000|         HR|\n",
      "|  6|   Frank|  Male| 80000|Engineering|\n",
      "|  7|   Grace|Female| 70000|  Marketing|\n",
      "|  8|   Henry|  Male| 62000|    Finance|\n",
      "|  9|     Ivy|Female| 68000|         HR|\n",
      "| 10|    Jack|  Male| 72000|Engineering|\n",
      "| 11|    Kate|Female| 48000|  Marketing|\n",
      "| 12|     Leo|  Male| 85000|    Finance|\n",
      "| 13|     Mia|Female| 61000|         HR|\n",
      "| 14|  Nathan|  Male| 77000|Engineering|\n",
      "| 15|  Olivia|Female| 69000|  Marketing|\n",
      "| 16|   Peter|  Male| 53000|    Finance|\n",
      "| 17|   Quinn|Female| 62000|         HR|\n",
      "| 18|    Ryan|  Male| 74000|Engineering|\n",
      "| 19|Samantha|Female| 68000|  Marketing|\n",
      "| 20|     Tom|  Male| 58000|    Finance|\n",
      "+---+--------+------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "groupby functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method groupBy in module pyspark.sql.dataframe:\n",
      "\n",
      "groupBy(*cols: 'ColumnOrName') -> 'GroupedData' method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Groups the :class:`DataFrame` using the specified columns,\n",
      "    so we can run aggregation on them. See :class:`GroupedData`\n",
      "    for all the available aggregate functions.\n",
      "    \n",
      "    :func:`groupby` is an alias for :func:`groupBy`.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    cols : list, str or :class:`Column`\n",
      "        columns to group by.\n",
      "        Each element should be a column name (string) or an expression (:class:`Column`)\n",
      "        or list of them.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`GroupedData`\n",
      "        Grouped data by given columns.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = spark.createDataFrame([\n",
      "    ...     (2, \"Alice\"), (2, \"Bob\"), (2, \"Bob\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n",
      "    \n",
      "    Empty grouping columns triggers a global aggregation.\n",
      "    \n",
      "    >>> df.groupBy().avg().show()\n",
      "    +--------+\n",
      "    |avg(age)|\n",
      "    +--------+\n",
      "    |    2.75|\n",
      "    +--------+\n",
      "    \n",
      "    Group-by 'name', and specify a dictionary to calculate the summation of 'age'.\n",
      "    \n",
      "    >>> df.groupBy(\"name\").agg({\"age\": \"sum\"}).sort(\"name\").show()\n",
      "    +-----+--------+\n",
      "    | name|sum(age)|\n",
      "    +-----+--------+\n",
      "    |Alice|       2|\n",
      "    |  Bob|       9|\n",
      "    +-----+--------+\n",
      "    \n",
      "    Group-by 'name', and calculate maximum values.\n",
      "    \n",
      "    >>> df.groupBy(df.name).max().sort(\"name\").show()\n",
      "    +-----+--------+\n",
      "    | name|max(age)|\n",
      "    +-----+--------+\n",
      "    |Alice|       2|\n",
      "    |  Bob|       5|\n",
      "    +-----+--------+\n",
      "    \n",
      "    Group-by 'name' and 'age', and calculate the number of rows in each group.\n",
      "    \n",
      "    >>> df.groupBy([\"name\", df.age]).count().sort(\"name\", \"age\").show()\n",
      "    +-----+---+-----+\n",
      "    | name|age|count|\n",
      "    +-----+---+-----+\n",
      "    |Alice|  2|    1|\n",
      "    |  Bob|  2|    2|\n",
      "    |  Bob|  5|    1|\n",
      "    +-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.groupBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = df.groupBy(col(\"dept\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.group.GroupedData"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can do aggrigation on groupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = group.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       dept|count|\n",
      "+-----------+-----+\n",
      "|Engineering|    8|\n",
      "|         HR|    8|\n",
      "|    Finance|    7|\n",
      "|  Marketing|    7|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupBy(col(\"gender\"), col(\"dept\")).max(\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----------+\n",
      "|gender|       dept|max(salary)|\n",
      "+------+-----------+-----------+\n",
      "|Female|         HR|      68000|\n",
      "|  Male|  Marketing|      50000|\n",
      "|  Male|    Finance|      90000|\n",
      "|Female|  Marketing|      70000|\n",
      "|  Male|Engineering|      80000|\n",
      "+------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= df.groupBy(col(\"gender\"), col(\"dept\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----+\n",
      "|gender|       dept|count|\n",
      "+------+-----------+-----+\n",
      "|Female|         HR|    8|\n",
      "|  Male|  Marketing|    1|\n",
      "|  Male|    Finance|    7|\n",
      "|Female|  Marketing|    6|\n",
      "|  Male|Engineering|    8|\n",
      "+------+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+----+\n",
      "| id|name|gender|salary|dept|\n",
      "+---+----+------+------+----+\n",
      "+---+----+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = df.filter((col(\"gender\") == \"Male\") & (col(\"dept\") == \"HR\"))\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
