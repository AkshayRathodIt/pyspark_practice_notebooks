{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/22 12:13:45 WARN Utils: Your hostname, akshay-vm resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "24/06/22 12:13:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/22 12:13:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/home/akshay/spark-3.5.1-bin-hadoop3')\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"spark_tutorials_1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_data = [\n",
    "    (1, 'John Doe', 1001, 50000),\n",
    "    (2, 'Jane Smith', 1002, 60000),\n",
    "    (3, 'Michael Johnson', 1001, 55000),\n",
    "    (4, 'Emily Davis', 1003, 65000),\n",
    "    (5, 'David Brown', 1002, 62000),\n",
    "    (6, 'Sarah Clark', 1003, 68000),\n",
    "    (7, 'Kevin Lee', 1001, 51000),\n",
    "    (8, 'Rachel Wilson', 1002, 59000),\n",
    "    (9, 'Jason Martinez', 1001, 54000),\n",
    "    (10, 'Laura Garcia', 1003, 70000),\n",
    "    (11, 'Daniel Anderson', 1002, 63000),\n",
    "    (12, 'Maria Rodriguez', 1003, 69000),\n",
    "    (13, 'Eric Wright', 1001, 52000),\n",
    "    (14, 'Olivia Thomas', 1003, 71000),\n",
    "    (15, 'Andrew Scott', 1002, 60000),\n",
    "    (16, 'Sophia Allen', 1004, 58000),   # New employee\n",
    "    (17, 'Thomas Baker', 1001, 56000),   # New employee\n",
    "    (18, 'Jessica White', 1004, 59000),  # New employee\n",
    "    (19, 'Ryan King', 1002, 64000),      # New employee\n",
    "    (20, 'Emma Young', 1004, 62000)  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_schema = [\"_emp_id\",\"emp_name\",\"dept_id\",\"emp_salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = spark.createDataFrame(data=employee_data, schema=employee_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------+----------+\n",
      "|_emp_id|       emp_name|dept_id|emp_salary|\n",
      "+-------+---------------+-------+----------+\n",
      "|      1|       John Doe|   1001|     50000|\n",
      "|      2|     Jane Smith|   1002|     60000|\n",
      "|      3|Michael Johnson|   1001|     55000|\n",
      "|      4|    Emily Davis|   1003|     65000|\n",
      "|      5|    David Brown|   1002|     62000|\n",
      "|      6|    Sarah Clark|   1003|     68000|\n",
      "|      7|      Kevin Lee|   1001|     51000|\n",
      "|      8|  Rachel Wilson|   1002|     59000|\n",
      "|      9| Jason Martinez|   1001|     54000|\n",
      "|     10|   Laura Garcia|   1003|     70000|\n",
      "|     11|Daniel Anderson|   1002|     63000|\n",
      "|     12|Maria Rodriguez|   1003|     69000|\n",
      "|     13|    Eric Wright|   1001|     52000|\n",
      "|     14|  Olivia Thomas|   1003|     71000|\n",
      "|     15|   Andrew Scott|   1002|     60000|\n",
      "|     16|   Sophia Allen|   1004|     58000|\n",
      "|     17|   Thomas Baker|   1001|     56000|\n",
      "|     18|  Jessica White|   1004|     59000|\n",
      "|     19|      Ryan King|   1002|     64000|\n",
      "|     20|     Emma Young|   1004|     62000|\n",
      "+-------+---------------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for departments\n",
    "department_data = [\n",
    "    (1001, 'HR'),\n",
    "    (1002, 'IT'),\n",
    "    (1003, 'Finance'),\n",
    "    (1005, \"sales\"),\n",
    "    (1006, \"Marketing\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_schema = [\"dept_id\",\"dept_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|dept_id|dept_name|\n",
      "+-------+---------+\n",
      "|   1001|       HR|\n",
      "|   1002|       IT|\n",
      "|   1003|  Finance|\n",
      "|   1005|    sales|\n",
      "|   1006|Marketing|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_df = spark.createDataFrame(data=department_data, schema=dept_schema)\n",
    "dept_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "semileft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------+----------+\n",
      "|_emp_id|       emp_name|dept_id|emp_salary|\n",
      "+-------+---------------+-------+----------+\n",
      "|      1|       John Doe|   1001|     50000|\n",
      "|      3|Michael Johnson|   1001|     55000|\n",
      "|      7|      Kevin Lee|   1001|     51000|\n",
      "|      9| Jason Martinez|   1001|     54000|\n",
      "|     13|    Eric Wright|   1001|     52000|\n",
      "|     17|   Thomas Baker|   1001|     56000|\n",
      "|      2|     Jane Smith|   1002|     60000|\n",
      "|      5|    David Brown|   1002|     62000|\n",
      "|      8|  Rachel Wilson|   1002|     59000|\n",
      "|     11|Daniel Anderson|   1002|     63000|\n",
      "|     15|   Andrew Scott|   1002|     60000|\n",
      "|     19|      Ryan King|   1002|     64000|\n",
      "|      4|    Emily Davis|   1003|     65000|\n",
      "|      6|    Sarah Clark|   1003|     68000|\n",
      "|     10|   Laura Garcia|   1003|     70000|\n",
      "|     12|Maria Rodriguez|   1003|     69000|\n",
      "|     14|  Olivia Thomas|   1003|     71000|\n",
      "+-------+---------------+-------+----------+\n",
      "\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "left_semi_df = emp_df.join(dept_df, on=(emp_df.dept_id == dept_df.dept_id), how=\"leftsemi\")\n",
    "left_semi_df.show()\n",
    "print(left_semi_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leftanti join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-------+----------+\n",
      "|_emp_id|     emp_name|dept_id|emp_salary|\n",
      "+-------+-------------+-------+----------+\n",
      "|     16| Sophia Allen|   1004|     58000|\n",
      "|     18|Jessica White|   1004|     59000|\n",
      "|     20|   Emma Young|   1004|     62000|\n",
      "+-------+-------------+-------+----------+\n",
      "\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "left_anti_df = emp_df.join(dept_df, on=(emp_df.dept_id == dept_df.dept_id), how=\"left_anti\")\n",
    "left_anti_df.show()\n",
    "print(left_anti_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = [\n",
    "    (1, \"tony\", 0),\n",
    "    (2, \"vision\", 1),\n",
    "    (3, \"stev rojers\", 11),\n",
    "    (4, \"ant man\", 3),\n",
    "    (5, \"black panther\", 3),\n",
    "    (6, \"winter solder\", 3),\n",
    "    (7, \"falkan\", 1),\n",
    "    (8, \"black wido\", 1),\n",
    "    (9, \"spiderman\", 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = [\"super_id\",\"super_name\",\"leader_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=pdata, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+---------+\n",
      "|super_id|   super_name|leader_id|\n",
      "+--------+-------------+---------+\n",
      "|       1|         tony|        0|\n",
      "|       2|       vision|        1|\n",
      "|       3|  stev rojers|       11|\n",
      "|       4|      ant man|        3|\n",
      "|       5|black panther|        3|\n",
      "|       6|winter solder|        3|\n",
      "|       7|       falkan|        1|\n",
      "|       8|   black wido|        1|\n",
      "|       9|    spiderman|        1|\n",
      "+--------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_join_df = df.alias(\"sup_df\").join(df.alias(\"lead_df\"),\n",
    "                                       col(\"sup_df.leader_id\") == col(\"lead_df.super_id\"),\n",
    "                                       \"inner\") \\\n",
    "                                        .select(col(\"sup_df.super_name\").alias(\"superhero\"),\n",
    "                                                col(\"lead_df.super_name\").alias(\"leaderName\")\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|    superhero| leaderName|\n",
      "+-------------+-----------+\n",
      "|       vision|       tony|\n",
      "|       falkan|       tony|\n",
      "|   black wido|       tony|\n",
      "|    spiderman|       tony|\n",
      "|      ant man|stev rojers|\n",
      "|black panther|stev rojers|\n",
      "|winter solder|stev rojers|\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "self_join_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
